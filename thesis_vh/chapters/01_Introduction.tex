\chapter{Introduction}
\label{sec:intro}

%For exposes, create this chapter, plus start with chapter 2 (Related Work).

\section{Motivation}
\label{sec:intro:mo}
%\textbf{Why are we doing it? About 1 page.}
Process modeling is a common technique for a better understanding and documentation of organizational processes and structures, as well as for process improvements and standardizations. \cite{leopoldGeneratingNaturalLanguage2012} Processes are not only used in companies, but they are also common within organizations and in research. Usually, lots of process documentation are stored in natural language. \cite{friedrichProcessModelGeneration2011} Unfortunately, experience is necessary for process modeling, which creates a need for professional knowledge. BPMN2.0 is a standardized notation used to represent business processes graphically and is widely used in various industries and science. Process modeling is an elementary part of information systems and structural design. It is time-consuming, as 60\% of business process management is spent on modeling \cite{friedrichProcessModelGeneration2011}. Additionally, process descriptions and diagrams must be frequently adapted due to the constant optimization of processes. Furthermore, processes need to be adapted to new regulations \cite{winterAssessingComplianceBusiness2020}.
Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on enabling computers to understand, interpret, and produce human language (natural language). By applying NLP techniques, this project can enable the computer to understand natural language and to identify the relevant details from regulatory documents for the process \cite{winterAssessingComplianceBusiness2020}.  
Automated creation of process diagrams from textual descriptions is a promising approach to making processes more efficient and minimizing errors. This approach has already shown positive results in various application areas. 

However, there are only a few papers so far that explicitly deal with the extraction of process information from legal texts. Therefore, it is essential to focus on this application since law texts are often complex and Business Process Compliance (BPC) is due to the introduction of the General Data Protection Regulation (GDPR) and its financial fines for violations a highly relevant topic for companies \cite{sunDesigntimeBusinessProcess2023}.  Mostly, lawyers must interpret the legal text correctly and help implement internal company processes. Automating the creation of process diagrams from regulatory documents can facilitate the implementation of laws and standards and minimize errors. By comparing the automatically created process diagrams from legal texts with the process diagrams of, e.g., company processes, it would be possible to make the realization in companies and organizations easier to implement. Furthermore, the costs can be reduced since the productivity in the process analysis is high, as well as the expenditure for uniform documentation, lawyers, and conversion is more effortless.

With the combination of NLP for extracting relevant information from regulatory documents and BMPN2.0 for visualization, our approach aims to improve understanding of regulatory documents, facilitate implementation through visualization, and minimize errors due to misunderstandings. 
In summary, process modeling is an essential technique for understanding and improving organizational processes, but it can be time-consuming and requires specialized knowledge. Natural Language Processing (NLP) is a promising approach for automating process information extraction from textual descriptions. Automated process diagram creation has already shown positive results in various application areas. However, there is a need for more research specifically focused on the extraction of process information from legal texts. To address these gaps in the existing literature, this study aims to investigate the following research questions:
\pagebreak

\section{Research Questions}
\label{sec:intro:rq}
%At least 3 questions. They should not be answerable yes/no. Questions should be questions (1 sentence). But you are allowed to explain them in more detail.
%Ich w√ºrde RQ1 leicht anpassen "RQ 1: How can business process reference models be automatically generated from textual descriptions in regulatory documents using NLP techniques?"
 \textbf{TODO: In the explanation also tell how you plan to prove that your potential future solution is good. About 1 page.}
 
\textbf{RQ 1: How can business process models be automatically generated from textual descriptions using NLP techniques? }This research question aims to refactor the current state approach to automatically convert textual process descriptions into graphical representations using NLP techniques and to investigate the methods and techniques that can be employed. 

\textbf{RQ 2: How do recent developments compare to existing methods? }The second research question focuses on evaluating and comparing recent advancements in the field of automatic business process modeling, specifically those utilizing NLP techniques, with existing methods. It aims to assess the improvements, innovations, and potential advantages of these recent developments in terms of ease of use, model quality, and overall performance. By conducting a comparative analysis, this research question seeks to identify the strengths and limitations of the state-of-the-art approaches compared to established methods. 

\textbf{RQ 3: How well does the approach work concerning process descriptions from more complex regulatory documents (e.g., ISO Norms)? }This research question aims to assess the effectiveness and applicability of the proposed approach, specifically focusing on its performance when applied to more complex regulatory documents such as ISO Norms. It seeks to understand how well the NLP-based approach handles the challenges of intricate and detailed process descriptions within these regulatory documents. The research will evaluate the accuracy and ability of the approach to transform complex regulatory language into meaningful and accurate BPMN2.0 process diagrams. 

\textbf{RQ4: Which technologies best visualize the extracted process information in a BPMN2.0 process model?} This research question aims to explore the various technologies that can effectively visualize the process information extracted from textual descriptions in a BPMN2.0 process model. Once the relevant details have been extracted using Natural Language Processing (NLP) techniques, it is crucial to represent this information in a visually understandable and standardized format. The visualization of extracted process information plays a significant role, as it enables stakeholders to comprehend the process model easily and facilitates communication and collaboration among team members involved in process analysis, improvement, and implementation. The research will identify a best-practice technology for visualizing the extracted process information in a BPMN2.0 process model. Additionally, the research will explore any advancements or innovations in process visualization technologies that can enhance the representation and understanding of process models. Factors to consider include ease of use, flexibility in representing different process elements, support for BPMN2.0 notation, layout, and visualization quality. This understanding will contribute to the overall goal of improving the comprehension, implementation, and standardization of processes in organizations, ultimately leading to enhanced process efficiency, reduced errors, and better decision-making.
\pagebreak

\section{Contribution}
\label{sec:intro:con}

The significance of this work lies in the effort to investigate and further develop the basic approach formulated by [TODO: Shuawei]. This basic approach provides an instrumental solution based on the conversion of textual process descriptions into BPMN diagrams. While the foundation of the approach is embedded in the work of [TODO: Friedrich], the evaluation metrics were mainly taken from academic, industrial and textbook-based process descriptions. Against this background, the main contributions of this work can be highlighted as follows:

\begin{enumerate}
\item \textbf{Enhanced scope of the evaluation: }this study pioneers by attempting to evaluate the baseline approach using regulatory documents, in particular ISO standards and articles from the General Data Protection Regulation (GDPR). This extends the assessment framework to cover a diverse range of textual descriptions beyond traditional academic and industry boundaries.
\item \textbf{Identification of limitations: }By applying the program to evaluation data consisting of process descriptions and legal texts, this study systematically identifies the underlying limitations of the baseline approach. This insights are crucial as it identifies opportunities for improvement and adaptation, especially when dealing with texts that contain complicated legal nuances.
\item \textbf{Differential analysis:} The research analyses the differences between regulatory documents and traditional business process descriptions. Understanding these contrasts is crucial as it sheds light on the inherent complexity and specifications of regulatory documents that may not be present in standard process descriptions and provides insight into possible contextual adaptations.
\item \textbf{Strategic adjustments}: Given the limitations and differences uncovered, this work takes the next logical step by implementing possible strategies and methods for fine-tuning the automatic generation of business processes. By addressing the characteristics of legal texts, it provides a road map for refining and improving the tool's adaptability and accuracy.
\end{enumerate}

In essence, this work is a bridge that connects the fields of business process modelling and legal regulatory documentation. It strives to improve the capabilities of the basic tool, highlight the specifics of regulatory text, and ensure that it is robust and versatile enough to handle a broader and more complex range of textual descriptions.

Through comprehensive assessment and detailed analysis, this study aims to strengthen [TODO: Shuawei]'s foundational work and ensure that it is equipped to meet the challenges of an evolving text landscape.

%What will/have I do/done that nobody else has done before. About 1/2 page.

%Als basis nimmst du Shuaiweis arbeit und schaust von da aus ausgehend a) was sind open challenges/ funktioniert bei ihm noch nciht so gut b) wie unterscheiden sich legal texts von den bei Shuaiwei behandelten process descriptions (da gibt es auch schon arbeiten/ auflistungen zu) c) wie kann man diese Unterschiede adressieren/ wie muss man die implementierung anpassen, damit die besonderen merkmale von legal texten ber√ºcksichtigt werden


%Bring it from Java to Python
% Evaluate the quality of the outputs for first time in regard to regulatory documents
% developed a tool that takes textual description as input and automatically generates a BPMN as output
%work is based on Friedrich is the state of the art
%Using spacy
% Determinate potential for regulatory texts

\pagebreak

\section{Methodology}
\label{sec:intro:meth}

%Design Science in Information System (Hevner). How are we doing research? (1) Summary what design science is (it uses stakeholders, artefacts, steps, ...). (2) What are the stakeholders, artefacts, steps for MY case. About 1.5 pages.}

As an implementation project is the core of the thesis, we will follow the design science research (DSR) methodology proposed by Hevner \cite{hevnerDesignScienceInformation2008}, \cite{vombrockeIntroductionDesignScience2020} \cite{peffersDesignScienceResearch}. This guides developing and evaluating our solutions to problems described in Chapter 1. The DSR approach is iterative and involves designing, building, evaluating, and refining an artifact until a satisfactory solution is achieved. This chapter will describe the DSR methodology we use in this study.

The DSR method consists of six stages, as follows: \begin{enumerate}
\item	problem identification and motivation
\item	definition of the objectives for a solution
\item	design and development 
\item	demonstration 
\item	evaluation
\item	communication
\end{enumerate}
In the following, it is explained how the six stages will be applied within the project:

\subsection{Problem identification and motivation}
In the DSR methodology, the initial step is to recognize the issue and establish the reason for the study. Research in the literature (as seen in the next chapter) indicates that no modern solution is currently available for automatically generating process diagrams. Specifically, there is no investigation of the possibility of automatically generating process diagrams from regulatory documents. This study aims to develop an automated approach to extract relevant data from regulatory documents and create process diagrams. This will enhance understanding and implementation of regulations while also reducing mistakes.

\subsection{Definition of the objectives for a solution}
The second step in the DSR methodology is to define objectives. This thesis aims to develop an enhanced proven method for automatically generating process models from a textual description using current technologies. For this purpose, given approaches will be evaluated, and the most advanced approach will be reconstructed. Here, the aim is to evaluate the accuracy, compared to the approach to be followed, as well as to minimize or eliminate errors and improve the output quality. Additionally, this thesis focuses on analyzing the approach for creating process diagrams of regulatory documents and improving the implemented algorithm for this purpose.

\subsection{Design and development}
The third step in the DSR methodology is to design and develop the artifact. In our case, we develop a prototype that uses NLP techniques to extract relevant information from regulatory documents and create process diagrams (BPMN 2.0 models). The software prototype will be developed using Python programming language, Spacy library for NLP processing, and the BPMN 2.0 standard for the visualization of processes.

\subsection{Demonstration} 
The fourth step in the DSR methodology is to demonstrate and evaluate the artifact. In our case, we demonstrated the developed Python code by using it to extract relevant information from a set of example regulatory documents and create process diagrams. Afterward, we evaluated the results of this proof-of-concept implementation based on the accuracy and completeness of the process models. The code will be published on GitHub, accessible to all stakeholders. Additionally, a set of natural process descriptions and human-modeled process diagrams, which have been used for the evaluation, will be published there as well, together with the output diagrams created by the algorithm.

\subsection{Evaluation}
The fifth step in the DSR methodology is to evaluate the artifact. The created approach will be evaluated by checking the completeness and the correct order of the process steps. Therefore, a set of text-based descriptions, corresponding human-modeled process diagrams, and the results of the automatically generated models will be compared to measure the accuracy with the help of an evaluation matrix.

\subsection{Communication}
Finally, the last step is to communicate the results. The outcomes of this project will be presented in a scientific paper (thesis). As mentioned in the demonstration part of DSR, the code will be accessible with some examples in a GitHub repository. Additionally, this thesis will be communicated and presented in a thesis defense to all relevant stakeholders.

\pagebreak

\section{Evaluation}
\label{sec:intro:ev}
%How will I evaluate that my proposal is good. This ties into the research questions. About 1 page.

The evaluation aims to assess the performance and effectiveness of the proposed approach in addressing the research objectives outlined in Chapter 1, thereby providing critical insights into its practical application and potential impact on process modeling. 

This approach focuses on qualitative evaluation since quantitative decision criteria such as runtime are superior to human creation. Additionally, the runtime is not comparable to the outcomes of Friedrich et al. due to the hardware progress within the last decade. 

A set of qualified input data from several sources will be collected. We will also use the same input data as Friedrich et al. to ensure comparability to the results. Afterward, this approach focuses on the evaluation of regulatory documents. Therefore, we will use descriptions of ISO norms and the General Data Protection Regulation (GDPR).

Criteria for selecting the test data are a textual process description and a corresponding BPMN model created by a human model, which will be used as the gold standard. In the following, we will call these sets ‚Äútext-model pairs‚Äù. 

As evaluation metrics, we will use the \textbf{Graph edit distance (\(GED \))} to compare the similarity of the different outputs. The graph edit distance between two graphs, \(g_1 \) and \(g_2 \), is written as \(GED\left(g_1, g_2\right) \).  \(GED\left(g_1, g_2\right) \) is minimum of editing operations to transform \(g_1 \) into \(g_2 \) and is denoted as
\begin{equation}
GED\left(g_1, g_2\right)=\min _{\left(e_1, \ldots, e_k\right) \in \mathcal{P}\left(g_1, g_2\right)} \sum_{i=1}^k c\left(e_i\right)
\end{equation}

where  \(P\left(g_1, g_2\right) \) denotes the number of edits \((|e|)\) multiplicated by the costs \((c)\) per edit type to transform  \(g_1 \)  into \(g_2 \) and is the cost of each graph edit operation \cite{abu-aishehExactGraphEdit2015}.

For calculating  \(GED\left(g_1, g_2\right) \)the following steps will be performed:

\begin{enumerate}
\item  \textbf{Definition of edit operations:} Operations can be adding or removing Nodes (N), Gateways (G), or Edges (E). Other activities could be changing the order of activities (OA), renaming activities (RA), or splitting activities (SA). \( \{N, G, E, OA , RA, SA\} \in e \) 
\item  \textbf{Assigning costs to the operations:} Assigning costs to each edit operation based on the complexity and significance of the process. For example, the costs of adding or removing a node are written as \(C(|N|)\) .
\item  \textbf{Calculating the graph edit distance:} Using the graph edit distance algorithm, to calculate the minimum required cost to transform the graph \(g_1 \)  to the graph \(g_2 \). 
\end{enumerate}
The result of the graph edit distance algorithm is the minimum required costs of transforming our automatically created process model to the human model process model. It enables us to compare the different approaches in terms of the similarity of the outcomes.

This technique is used, to determine  
\begin{equation}
GED1\left(g_{\text {ourApproach }}, g_{\text {human-modeld}}\right)
\end{equation}

and

\begin{equation}
GED2\left(g_{\text {Friedrich }}, g_{\text {human-modeld}}\right).
\end{equation}
As the result of the GED represents the similarity of an approach to the gold standard, we will be able to compare the accuracy of GED1 and GED2. This evaluation will be done using the text-model pairs used by Friedrich et al. 

Afterward, the results of our approach will be compared to the results of human-modeled diagrams based on the text-model pairs of \textbf{regulatory documents} 
\begin{equation}
GED3\left(g_{\text {ourApproach }}, g_{\text {human-modeld}}\right).
\end{equation}

Within the evaluation, the results of this approach will be represented, and the limitations of this approach will be identified and discussed. The outcomes will be compared to related work to identify similarities, differences, and potential explanations for variations. Unsolved questions and challenges that emerged during the project will be outlined, and suggestions about further research or improvements will be prepared.
\pagebreak

\section{Structure}
\label{sec:intro:struct}
TODO: Neuformulieren / Anpassen
The remainder of this paper is structured as follows. Section¬†2 discusses related works. Section¬† 3 introduces related definitions and problem of this work. Section¬† 4 describes the proposed methods to improve the accuracy of the generated process diagrams and adaptions to achieve improved results, if the input are regulatory documents. Section¬† 5 evaluates and compares the proposed approach with existing methods and evaluates our approach on a dataset. Section¬†6 provides a brief overview of the threats to validation. Finally, Sect.¬†7 shows the conclusions and future work.

%Which chapters will my thesis have, and what are they all about.
%About 1/4 page.
\pagebreak
